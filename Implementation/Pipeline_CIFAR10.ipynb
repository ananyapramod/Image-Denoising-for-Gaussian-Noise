{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1eE2EMHAU7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaee4f1e-bf3e-4269-c37c-74cdd2d47697"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "import pickle\n",
        "import keras \n",
        "from keras.datasets import cifar10, mnist\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Conv1D, Conv3D, Input, Activation, Subtract, MaxPool2D, UpSampling2D\n",
        "import tensorflow\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from math import log10, sqrt \n",
        "from keras.utils.np_utils import to_categorical  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQAq0sDBEXgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import datasets needed\n",
        "\n",
        "(train_images_raw,train_label),(test_images_raw,test_label)=cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IcDeMn5EbSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert labels into one-hot-encoded vectors\n",
        "def label_vectors():\n",
        "  train_labels=to_categorical(train_label,num_classes=10)\n",
        "  test_labels=to_categorical(test_label, num_classes=10)\n",
        "  return train_labels, test_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob3Yj-OGElj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to add noise\n",
        "def add_gauss(img):\n",
        "  noise_added_images=[]\n",
        "  for i in range(len(img)):\n",
        "    noise_added_images.append(img[i]+1.5*np.random.normal(0,0.1,(32,32,3)))\n",
        "  return noise_added_images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iOB03PHE7ML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def statistical_filter(img):\n",
        "  filtered_images=[]\n",
        "  for i in range(len(img)):\n",
        "    my_img=img[i]\n",
        "    X=cv2.GaussianBlur(my_img,(5,5),cv2.BORDER_DEFAULT)\n",
        "    filtered_images.append(X)\n",
        "  return filtered_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDvxSswwFE4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_denoiser(train_images_noisy,train_images):\n",
        "  dilation=[1,1,1,1,1,1,1]\n",
        "  filter_size=[32,32,64,64,128,64,64]\n",
        "  input_image= Input(shape=(28,28,1))\n",
        "  x= Conv2D(64,kernel_size=3,activation=\"relu\",dilation_rate=1,strides=(1,1),padding=\"same\")(input_image)\n",
        "  \n",
        "  for layers in range(7):\n",
        "    x=Conv2D(64,kernel_size=3, strides=(1,1),dilation_rate=1,padding=\"same\")(x)\n",
        "    x= BatchNormalization(axis=-1,epsilon=0.001 )(x)\n",
        "    x=Activation(\"relu\")(x)\n",
        "\n",
        "  x=Conv2D(1, kernel_size=3,strides=(1,1),dilation_rate=1,padding=\"same\")(x)\n",
        "  x=Subtract()([input_image,x])\n",
        "  model=Model(inputs=input_image, outputs=x)\n",
        "  #model.compile(optimizer=\"Adam\", loss=[\"mean_squared_logarithmic_error\"])\n",
        "  model.compile(optimizer=\"Adam\", loss=[\"mse\"])\n",
        "  \n",
        "  A=np.array(train_images_noisy)\n",
        "  B=np.array(train_images)\n",
        "  model.fit(A,B,epochs=2)\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWtiJd2sGQTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(input_img):\n",
        "    \"\"\"\n",
        "    Encoder function.\n",
        "    Arguments:\n",
        "      input_img: Input image, Tensor of shape (28, 28, 1)\n",
        "    \n",
        "    Returns: Encoded image, Tensor of shape (7, 7, 8)\n",
        "    \"\"\"\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='encoder_conv1')(input_img)\n",
        "    x = MaxPool2D((2, 2), padding='same', name='encoder_pool1')(x)\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='encoder_conv2')(x)\n",
        "    x = MaxPool2D((2, 2), padding='same', name='encoder_pool2')(x)\n",
        "    encoded = Conv2D(8, (3, 3), activation='relu', padding='same', name='encoder_conv3')(x)\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def decoder(encoded):\n",
        "    \"\"\"\n",
        "    Decoder function.\n",
        "    Arguments:\n",
        "      encoded: Encoded image, Tensor of shape (7, 7, 8)\n",
        "    \n",
        "    Returns: Decoded images, Tensor of shape (28, 28, 1)\n",
        "    \"\"\"\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='decoder_conv1')(encoded)\n",
        "    x = UpSampling2D((2, 2), name='decoder_upsample1')(x)\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='decoder_conv2')(x)\n",
        "    x = UpSampling2D((2, 2), name='decoder_upsample2')(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='decoder_conv3')(x)\n",
        "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='decoder_conv4')(x)\n",
        "    return decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6mQJm78GQcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def autoencoder_denoiser(x_train_noisy,x_train_expanded,x_test_noisy,x_test_expanded):\n",
        "  input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "  #create autoencoder model\n",
        "  autoencoder = Model(input_img, decoder(encoder(input_img)))\n",
        "  #complile model\n",
        "  autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "  #define callback for earlystopping to stop training if the validation loss does not decrese for 10 epochs \n",
        "  earlyStopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "  #define callback to save model weights if the validation loss improves\n",
        "  modelChkpt = ModelCheckpoint(filepath='best_weights.h5', monitor='val_loss', save_best_only=True) \n",
        "\n",
        "  #train model\n",
        "  train_history = autoencoder.fit(x_train_noisy, x_train_expanded,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test_expanded),callbacks=[modelChkpt, earlyStopping])\n",
        "  return autoencoder\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9mHmJEkFPCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##classification model for noisy images\n",
        "def classification(train_images,train_labels,test_images,test_labels):\n",
        "  early_stop=[EarlyStopping(patience=2)]\n",
        "  model=Sequential()\n",
        "  model.add(Conv2D(32,kernel_size=3,activation='relu', input_shape=(32,32,3)))\n",
        "  model.add(Conv2D(128, kernel_size=3,activation='relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "  train_images=np.array(train_images)\n",
        "  test_images=np.array(test_images)\n",
        "  \n",
        "  model.fit(train_images,train_labels,validation_data=(test_images,test_labels),epochs=10)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klI4i4d3esyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = test_images_raw.astype('float32') / 255.0\n",
        "train_images= train_images_raw.astype('float32') / 255.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNM8QphFoUr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = np.expand_dims(train_images_raw, axis=3)\n",
        "test_images = np.expand_dims(test_images_raw, axis=3)  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zng5Qu1BqEdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noisy_test_images=add_gauss(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipVXwoSAoeny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noisy_train_images=add_gauss(train_images)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cTttfC4I5I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels, test_labesl=label_vectors()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNj5eAqxnNIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_images_train=statistical_filter(noisy_train_images)\n",
        "filtered_images_test=statistical_filter(noisy_test_images)\n",
        "autoencoder=autoencoder_denoiser(np.array(filtered_images_train),np.array(train_images), np.array(filtered_images_test),np.array(test_images))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMKUEWChpKRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.array(noisy_train_images).shape)\n",
        "train_images_expanded = np.expand_dims(train_images, axis=3)\n",
        "  test_images_expanded = np.expand_dims(test_images, axis=3) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFT68o4rb3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_noisy=classification(noisy_train_images,train_labels,noisy_test_images,test_labesl)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVBoWMOrsjTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_images_train=np.expand_dims(filtered_images_train,axis=3)\n",
        "filtered_images_test=np.expand_dims(filtered_images_test,axis=3)\n",
        "model_denoised=classification(filtered_images_train,train_labels,filtered_images_test,test_labesl)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqbR2_chtn8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "im1 = tf.image.convert_image_dtype(noisy_test_images, tf.float32)\n",
        "im2 = tf.image.convert_image_dtype(filtered_images_test, tf.float32)\n",
        "psnr = tf.image.psnr(im1, im2, max_val=1.0)\n",
        "psnr_train = np.mean(psnr)\n",
        "print(psnr_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}